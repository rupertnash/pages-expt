<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Rupert Nash, Kevin Stratford, Alan Gray">
  <title>Your first CUDA program</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../reveal.js/css/theme/black.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '../../reveal.js/css/print/pdf.css' : '../../reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="../../reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Your first CUDA program</h1>
  <p class="author">Rupert Nash, Kevin Stratford, Alan Gray</p>
</section>

<section><section id="introduction" class="title-slide slide level1"><h1>Introduction</h1></section><section id="viewing-these-notes" class="slide level2">
<h2>Viewing these notes</h2>
<ul>
<li>As <a href="README.md">Markdown</a></li>
<li>As <a href="intro.pdf">PDF</a></li>
<li>As <a href="intro.html">slideshow</a></li>
</ul>
</section><section id="credits" class="slide level2">
<h2>Credits</h2>
<p>Lab created by EPCC, The University of Edinburgh. Documentation and source code copyright The University of Edinburgh 2016. Lab style and template created by NVIDIA, see <a href="https://nvidia.qwiklab.com/" class="uri">https://nvidia.qwiklab.com/</a>.</p>
</section><section id="purpose" class="slide level2">
<h2>Purpose</h2>
<p>In this lab, you will learn how to adapt a simple code such that it uses the GPU.</p>
<p>It has the purpose of negating an array of integers. We introduce the important concepts of device-memory management and kernel invocation. The final version should copy an array of integers from the host to device, multiply each element by -1 on the device, and then copy the array back to the host.</p>
<p>Choose the C or Fortran version.</p>
</section><section id="source-code" class="slide level2">
<h2>Source code</h2>
<p>You can get this from GitHub:</p>
<pre><code>git clone https://github.com/rupertnash/pages-expt.git
cd pages-expt/exercises/cuda-intro/</code></pre>
</section><section id="note" class="slide level2">
<h2>Note</h2>
<p>The template source file is clearly marked with the sections to be edited, e.g.</p>
<pre><code>  /* Part 1A: allocate device memory */
  </code></pre>
<p>Where necessary, you should refer to the CUDA C Programming Guide and Reference Manual documents available from <a href="http://developer.nvidia.com/nvidia-gpu-computing-documentation" class="uri">http://developer.nvidia.com/nvidia-gpu-computing-documentation</a>.</p>
</section></section>
<section><section id="part-1" class="title-slide slide level1"><h1>Part 1</h1></section><section id="copying-between-host-and-device" class="slide level2">
<h2>Copying Between Host and Device</h2>
</section></section>
<section><section id="c" class="title-slide slide level1"><h1>C</h1></section><section id="a" class="slide level2">
<h2>1A</h2>
<p>Allocate memory for the array on the device: use the existing pointer <code>d_a</code> and the variable <code>sz</code> (which has already been assigned the size of the array in bytes).</p>
</section><section id="b" class="slide level2">
<h2>1B</h2>
<p>Copy the array <code>h_a</code> on the host to <code>d_a</code> on the device.</p>
</section><section id="c-1" class="slide level2">
<h2>1C</h2>
<p>Copy <code>d_a</code> on the device back to <code>h_out</code> on the host.</p>
</section><section id="d" class="slide level2">
<h2>1D</h2>
<p>Free <code>d_a</code>.</p>
</section></section>
<section><section id="fortran" class="title-slide slide level1"><h1>Fortran</h1></section><section id="a-1" class="slide level2">
<h2>1A</h2>
<p>Allocate memory for the array on the device: use the existing pointer <code>d_a</code> and <code>ARRAY_SIZE</code> (which has already been assigned the size of the array in elements)</p>
</section><section id="b-1" class="slide level2">
<h2>1B</h2>
<p>Copy the array <code>h_a</code> on the host to <code>d_a</code> on the device, using an appropriate assignment operation.</p>
</section><section id="c-2" class="slide level2">
<h2>1C</h2>
<p>Copy <code>d_a</code> on the device back to <code>h_out</code> on the host, using another assignment operation.</p>
</section><section id="d-1" class="slide level2">
<h2>1D</h2>
<p>Deallocate <code>d_a</code>.</p>
</section></section>
<section><section id="compilation" class="title-slide slide level1"><h1>Compilation</h1></section><section id="load-modules" class="slide level2">
<h2>Load modules</h2>
<p>For C/C++</p>
<pre class="shell"><code>module load gcc cuda</code></pre>
<p>Fortran also required the PGI compilers</p>
<pre class="shell"><code>module load gcc cuda pgi</code></pre>
</section><section id="use-make" class="slide level2">
<h2>Use make</h2>
<p>Compile the code using <code>make</code>. Note that the compute capability of the CUDA device is specified with the <code>-arch</code> flag for C and with <code>-March=</code> for Fortran.</p>
</section></section>
<section><section id="running" class="title-slide slide level1"><h1>Running</h1></section><section id="on-cirrus" class="slide level2">
<h2>On Cirrus</h2>
<p>You can only run on the backend nodes, so you can submit the job to the batch system with <code>qsub submit.sh</code></p>
</section><section class="slide level2">

<p>During tutorials we have reserved one node (4 GPUs) for the use of the class. You can access this by editing the PBS script to use the reserved queue. This will be given in the class.</p>
</section><section class="slide level2">

<p>The output (the contents of the <code>h_out</code> array) or any error messages will be printed. So far the code simply copies from <code>h_a</code> on the host to <code>d_a</code> on the device, then copies <code>d_a</code> back to <code>h_out</code>, so the output should be the initial content of <code>h_a</code> - the numbers 0 to 255.</p>
</section></section>
<section><section id="part-2" class="title-slide slide level1"><h1>Part 2</h1></section><section id="launching-kernels" class="slide level2">
<h2>Launching Kernels</h2>
<p>Now we will actually run a kernel on the GPU device.</p>
</section></section>
<section><section id="c-3" class="title-slide slide level1"><h1>C</h1></section><section id="a-2" class="slide level2">
<h2>2A</h2>
<p>Configure and launch the kernel using a 1D grid and a single thread block (<code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> are already defined for this case).</p>
</section><section id="b-2" class="slide level2">
<h2>2B</h2>
<p>Implement the actual kernel function to negate an array element as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode c++"><code class="sourceCode cpp"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="dt">int</span> idx = threadIdx.x;</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">d_a[idx] = <span class="dv">-1</span> * d_a[idx];</a></code></pre></div>
<p>Compile and run the code as before. This time the output should contain the result of negating each element of the input array. Because the array is initialised to the numbers 0 to 255, you should see the numbers 0 down to -255 printed.</p>
</section><section class="slide level2">

<p>This kernel works, but since it only uses one thread block, it will only be utilising one of the multiple SMs available on the GPU. Multiple thread blocks are needed to fully utilize the available resources.</p>
</section><section id="c-4" class="slide level2">
<h2>2C</h2>
<p>Implement the kernel again, this time allowing multiple thread blocks. It will be very similar to the previous kernel implementation except that the array index will be computed differently:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode c++"><code class="sourceCode cpp"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="dt">int</span> idx = threadIdx.x + (blockIdx.x * blockDim.x);</a></code></pre></div>
</section><section class="slide level2">

<p>Remember to also change the kernel invocation to invoke negate_multiblock this time. With this version you can change <code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> to have different values - so long as they still multiply to give the array size.</p>
</section></section>
<section><section id="fortran-1" class="title-slide slide level1"><h1>Fortran</h1></section><section id="a-3" class="slide level2">
<h2>2A</h2>
<p>Configure and launch the kernel using a 1D grid and a single thread block (<code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> are already defined for this case).</p>
</section><section id="b-3" class="slide level2">
<h2>2B</h2>
<p>Implement the actual kernel function to negate an array element as follows:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="dt">integer</span> <span class="dt">::</span> idx</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">idx <span class="kw">=</span> threadidx%x</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">aa(idx) <span class="kw">=</span> <span class="kw">-</span><span class="dv">1</span><span class="kw">*</span>aa(idx)</a></code></pre></div>
<p>Compile and run the code as before. This time the output should contain the result of negating each element of the input array. Because the array is initialised to the numbers 0 to 255, you should see the numbers 0 down to -255 printed.</p>
</section><section class="slide level2">

<p>This kernel works, but since it only uses one thread block, it will only be utilising one of the multiple SMs available on the GPU. Multiple thread blocks are needed to fully utilize the available resources.</p>
</section><section id="c-5" class="slide level2">
<h2>2C</h2>
<p>Implement the kernel again, this time allowing multiple thread blocks. It will be very similar to the previous kernel implementation except that the array index will be computed differently:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb8-1" data-line-number="1">idx <span class="kw">=</span> threadidx%x <span class="kw">+</span> ((blockidx%x<span class="kw">-</span><span class="dv">1</span>) <span class="kw">*</span> blockdim%x)</a></code></pre></div>
</section><section class="slide level2">

<p>Remember to also change the kernel invocation to invoke g_negate_multiblock this time. With this version you can change <code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> to have different values - so long as they still multiply to give the array size.</p>
</section></section>
<section><section id="part-3" class="title-slide slide level1"><h1>Part 3</h1></section><section id="handling-any-size-array" class="slide level2">
<h2>Handling any size array</h2>
<p>Currently we are insisting that the array size be an exact multiple of the block size. In general we should handle any size that will fit in GPU memory!</p>
</section><section class="slide level2">

<p>Let the total number of elements be <span class="math inline">\(N\)</span> and the block size be <span class="math inline">\(B\)</span>.</p>
<p>Recall that in integer division we discard the fractional part so we can write:</p>
<p><span class="math display">\[N = k * B + r\]</span></p>
<p>i.e. <span class="math inline">\(N\)</span> can divided into <span class="math inline">\(k\)</span> (an integer) number of blocks, plus a remainder, <span class="math inline">\(r\)</span>. If <span class="math inline">\(r\)</span> is zero, then we need <span class="math inline">\(k\)</span> blocks, else we need <span class="math inline">\(k + 1\)</span>.</p>
</section><section class="slide level2">

<p>This can be expressed in a simple formula: <span class="math display">\[nBlocks = \frac{N-1}{B} + 1\]</span></p>
<p>Convince yourself this is correct!</p>
</section><section id="a-4" class="slide level2">
<h2>3A</h2>
<p>Update the kernel launch code to compute the number of blocks using this formula.</p>
<p>What will happen in the last block with the current kernel?</p>
</section><section id="b-4" class="slide level2">
<h2>3B</h2>
<p>Implement a condition in the kernel to protect against this.</p>
<p>Try changing <code>ARRAY_SIZE</code> to a non-multiple of 256 (e.g. 500).</p>
</section></section>
    </div>
  </div>

  <script src="../../reveal.js/lib/js/head.min.js"></script>
  <script src="../../reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: '../../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../../reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: '../../reveal.js/plugin/math/math.js', async: true },
          { src: '../../reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
